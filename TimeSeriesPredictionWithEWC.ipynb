{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3601, 500, 1), (3601,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    y = data[:, 0]\n",
    "    x = data[:, 1:]\n",
    "    return x, y.astype(int)\n",
    "\n",
    "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
    "\n",
    "X_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
    "X_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
    "\n",
    "X_train=X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
    "X_test=X_test.reshape((X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "X_train1=X_train[:2000]\n",
    "y_train1=y_train[:2000]\n",
    "\n",
    "X_train2=X_train[2000:]\n",
    "y_train2=y_train[2000:]\n",
    "\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 0.6943 - accuracy: 0.4837 - val_loss: 0.6965 - val_accuracy: 0.5025\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.6933 - accuracy: 0.5063 - val_loss: 0.6929 - val_accuracy: 0.5225\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.6923 - accuracy: 0.5344 - val_loss: 0.6951 - val_accuracy: 0.4850\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.6912 - accuracy: 0.5381 - val_loss: 0.6891 - val_accuracy: 0.5300\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.6922 - accuracy: 0.5225 - val_loss: 0.6888 - val_accuracy: 0.5450\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.6910 - accuracy: 0.5350 - val_loss: 0.6930 - val_accuracy: 0.5050\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 1s 27ms/step - loss: 0.6908 - accuracy: 0.5244 - val_loss: 0.6912 - val_accuracy: 0.5125\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.6899 - accuracy: 0.5344 - val_loss: 0.6891 - val_accuracy: 0.5300\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.6904 - accuracy: 0.5131 - val_loss: 0.6935 - val_accuracy: 0.5100\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6947 - val_accuracy: 0.4950\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 1s 27ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6930 - val_accuracy: 0.5075\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.7081 - accuracy: 0.5088 - val_loss: 0.7044 - val_accuracy: 0.5125\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.7034 - accuracy: 0.4881 - val_loss: 0.6958 - val_accuracy: 0.5450\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.7092 - accuracy: 0.4931 - val_loss: 0.7013 - val_accuracy: 0.4600\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.6972 - accuracy: 0.4844 - val_loss: 0.6907 - val_accuracy: 0.5300\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.6988 - accuracy: 0.4825 - val_loss: 0.7009 - val_accuracy: 0.4650\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.6978 - accuracy: 0.5113 - val_loss: 0.6971 - val_accuracy: 0.4550\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.6992 - accuracy: 0.5169 - val_loss: 0.7272 - val_accuracy: 0.4600\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.6949 - accuracy: 0.5188 - val_loss: 0.6939 - val_accuracy: 0.5125\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 1s 26ms/step - loss: 0.6963 - accuracy: 0.4938 - val_loss: 0.6980 - val_accuracy: 0.4650\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6999 - accuracy: 0.4859 - val_loss: 0.7016 - val_accuracy: 0.4486\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.7019 - accuracy: 0.4914 - val_loss: 0.7022 - val_accuracy: 0.4517\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.6966 - accuracy: 0.5133 - val_loss: 0.7087 - val_accuracy: 0.4673\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.6987 - accuracy: 0.4992 - val_loss: 0.6987 - val_accuracy: 0.5296\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.6990 - accuracy: 0.5109 - val_loss: 0.7049 - val_accuracy: 0.4486\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.6990 - accuracy: 0.5094 - val_loss: 0.6990 - val_accuracy: 0.4548\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.6991 - accuracy: 0.5109 - val_loss: 0.6979 - val_accuracy: 0.4673\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.6987 - accuracy: 0.4836 - val_loss: 0.6971 - val_accuracy: 0.4829\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.6987 - accuracy: 0.4891 - val_loss: 0.6967 - val_accuracy: 0.4984\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.7012 - accuracy: 0.5086 - val_loss: 0.6994 - val_accuracy: 0.4891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4e6d632198>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "class EWCLoss:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.star_vars = []\n",
    "\n",
    "    def compute_fisher(self, x, n_samples=100):\n",
    "        fisher = []\n",
    "        for v in range(len(self.model.trainable_variables)):\n",
    "            fisher.append(np.zeros(self.model.trainable_variables[v].shape))\n",
    "\n",
    "        for _ in range(n_samples):\n",
    "            # Sample data and compute gradients\n",
    "            idx = np.random.choice(x.shape[0], 1, replace=False)\n",
    "            sample = x[idx]\n",
    "            with tf.GradientTape() as tape:\n",
    "                preds = self.model(sample)\n",
    "                loss = BinaryCrossentropy()(sample, preds)\n",
    "            grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "\n",
    "            # Accumulate squared gradients\n",
    "            for v, g in zip(range(len(grads)), grads):\n",
    "                fisher[v] += np.square(g.numpy())\n",
    "\n",
    "        # Average and normalize\n",
    "        for v in range(len(fisher)):\n",
    "            fisher[v] /= n_samples\n",
    "            fisher[v] /= np.sum(fisher[v])\n",
    "\n",
    "        self.star_vars = [v.numpy() for v in self.model.trainable_variables]\n",
    "        self.fisher=fisher\n",
    "        return fisher\n",
    "\n",
    "    def ewc_loss(self, lam=10000):\n",
    "        def loss(y_true, y_pred):\n",
    "            base_loss = BinaryCrossentropy()(y_true, y_pred)\n",
    "            ewc_loss = 0\n",
    "            for v, var_star, fish in zip(self.model.trainable_variables, self.star_vars, self.fisher):\n",
    "                ewc_loss += tf.reduce_sum(fish * tf.square(var_star - v))\n",
    "            return base_loss + (lam / 2) * ewc_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "# Build the LSTM model for time series binary classification\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(128, input_shape=input_shape),\n",
    "        Dense(16,activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "\n",
    "\n",
    "model = create_model(input_shape)\n",
    "optimizer = Adam()\n",
    "\n",
    "\n",
    "# Train the model on the first task\n",
    "model.compile(optimizer, loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "model.fit(X_train1, y_train1, epochs=20, validation_split=0.2, batch_size=32)\n",
    "\n",
    "ewc_loss = EWCLoss(model)\n",
    "fisher = ewc_loss.compute_fisher(X_train)\n",
    "\n",
    "model.compile(optimizer, loss=ewc_loss.ewc_loss(), metrics=['accuracy'])\n",
    "model.fit(X_train2, y_train2, epochs=10, validation_split=0.2, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score: 0.492200551982149\n",
      "accuracy score: 0.5159090909090909\n",
      "confusion matrix: [[681   0]\n",
      " [639   0]]\n",
      "precision score: 0.0\n",
      "recall score: 0.0\n",
      "f1 score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyu/enter/envs/deeplearning/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,roc_auc_score,confusion_matrix,precision_score,recall_score,f1_score\n",
    "\n",
    "predy=model.predict(X_test)\n",
    "\n",
    "print('roc auc score:',roc_auc_score(y_test,predy))\n",
    "print('accuracy score:',accuracy_score(y_test,predy.astype(int)))\n",
    "print('confusion matrix:',confusion_matrix(y_test,predy.astype(int)))\n",
    "print('precision score:',precision_score(y_test,predy.astype(int)))\n",
    "print('recall score:',recall_score(y_test,predy.astype(int)))\n",
    "print('f1 score:',f1_score(y_test,predy.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
